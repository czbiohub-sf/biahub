# Tracking mode: either "2D" (uses projected Z-slices) or "3D" (full volumetric).
mode: "2D"

fov: "*/*/*"
# Z-slice range to extract. Use [-1, -1] to auto-compute a centered slice. If None, all planes are returned or the user-defined range is used.
z_range: [-1, -1]

# Name of the target channel used to name the tracking output label channel.
target_channel: nuclei_prediction
blank_frames_path: blank_frames.csv

# Input image configurations.
# Each entry defines one dataset with its path and channels to process.
input_images:

  # First input: predicted nuclei and membrane channels.
  - path: /path/to/virtual_staining.zarr
    channels:
      nuclei_prediction:
        # Z-projection using mean intensity
        - function: np.mean
          kwargs:
            axis: 1
          per_timepoint: False

        # Normalize intensity with gamma correction
        - function: ultrack.imgproc.normalize
          kwargs:
            gamma: 0.7

      membrane_prediction:
        - function: np.mean
          kwargs:
            axis: 1
          per_timepoint: False

        - function: ultrack.imgproc.normalize
          kwargs:
            gamma: 0.7

  # # Optional: load label masks directly with or without processing.
  # - path: /path/to/segmentation.zarr
  #   channels:
  #     nuclei_prediction_labels: []

  # Virtual channel: computed dynamically using prior outputs.
  # if path is null, the channel is computed dynamically using the prior outputs.
  - path: null
    channels:
      foreground:
        - function: ultrack.imgproc.detect_foreground
          input_channels:
            - nuclei_prediction
          kwargs:
            sigma: 60

      contour:
        - function: biahub.track.mem_nuc_contour
          input_channels:
            - nuclei_prediction
            - membrane_prediction
          kwargs: {}

# Configuration for Ultrack tracking algorithm.
# See: https://royerlab.github.io/ultrack/

tracking_config:

  # Segmentation parameters: controls object detection from foreground/contour maps.
  segmentation_config:
    min_area: 2800            # Minimum object area (pixels)
    max_area: 80000           # Maximum object area (pixels)
    n_workers: 10             # Number of CPU threads for segmentation
    min_frontier: 0.5         # Minimum frontier strength for boundaries
    max_noise: 0.00          # Maximum tolerated noise in segmentation

  # Linking parameters: controls how detections are connected across timepoints.
  linking_config:
    n_workers: 10             # Number of CPU threads for linking
    max_distance: 15          # Max distance (in pixels) to link objects
    distance_weight: -0.0001  # Cost penalty per pixel of distance
    max_neighbors: 3          # Maximum number of neighbors to evaluate per object

  # Global tracking parameters: controls optimization across time.
  tracking_config:
    n_threads: 14             # Threads used for global tracking optimization
    disappear_weight: -0.0001  # Penalty for object disappearance
    appear_weight: -0.001      # Penalty for new object appearance
    division_weight: -0.0001   # Penalty (or reward) for cell division events
    bias: 0.0001 
