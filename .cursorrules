# biahub Cursor Rules

You are an AI assistant helping with the biahub bioimage analysis project, a Python package for high-throughput data reconstruction on HPC clusters.

## Project Context
- **Purpose**: Bioimage analysis hub for reconstructing multimodal microscopy datasets
- **Target**: HPC clusters with Slurm workload management
- **Data Format**: OME-ZARR datasets for efficient parallelization
- **Main Interface**: Command-line interface (CLI) with multiple reconstruction commands
- **Python Version**: 3.10+

## Code Style & Quality Standards

### Python Code Standards
- **Line length**: 95 characters (as defined in pyproject.toml)
- **Code formatter**: Black (version 22.3.0)
- **Import sorting**: isort with black profile
- **Linting**: flake8 (~5.0) and pylint (~2.14)
- **String quotes**: Prefer single quotes (skip-string-normalization = true)
- **Target version**: Python 3.10+

### Import Guidelines
- Use absolute imports where possible
- Group imports: stdlib, third-party, local modules
- Scientific computing imports should follow conventions:
  ```python
  import numpy as np
  import pandas as pd
  import torch
  import matplotlib.pyplot as plt
  from scipy import ndimage
  ```

### Scientific Computing Best Practices
- **NumPy**: Use vectorized operations, avoid loops when possible
- **Arrays**: Prefer explicit dtype declarations for memory efficiency
- **PyTorch**: Use device-agnostic code (`tensor.to(device)`)
- **Memory management**: Be mindful of large arrays, use chunking for big datasets
- **OME-ZARR**: Follow zarr best practices for parallel I/O

### CLI Development Standards
- Use Click or argparse consistently with existing CLI patterns
- Follow the established pattern: input (`-i`), output (`-o`), config (`-c`)
- Include `--help` documentation for all commands
- Support both Slurm and local execution modes (`-l` flag)
- Validate file paths and configurations early
- Provide clear error messages and progress indicators

### Configuration Management
- Use YAML files for configuration (following existing patterns)
- Validate configurations using Pydantic models when possible
- Provide sensible defaults and clear documentation
- Include example configuration files

### Testing Guidelines
- Write tests using pytest
- Focus on testing CLI commands end-to-end
- Mock expensive computations and file I/O where appropriate
- Test with small synthetic datasets
- Ignore `examples/` directory in tests

### Documentation Standards
- Use Numpy-style docstrings
- Include parameter types and descriptions
- Document expected input/output data formats
- Include usage examples for CLI commands
- Reference scientific methods and papers where applicable

### File Organization
- Keep CLI commands in `biahub/cli/` directory
- Analysis routines in `biahub/analysis/`
- Configuration templates in appropriate subdirectories
- Follow the existing module structure

### HPC & Slurm Considerations
- Design functions to be stateless and parallelizable
- Use submitit for job submission when appropriate
- Handle timeouts and job failures gracefully
- Optimize for batch processing of large datasets
- Consider memory limits on compute nodes

### Dependencies & Compatibility
- Pin major versions only for dev dependencies
- Be conservative with new dependencies
- Consider compatibility with existing scientific Python ecosystem
- Test with specified dependency versions

### Error Handling
- Provide informative error messages for common issues
- Handle file I/O errors gracefully
- Validate data formats early in processing pipeline
- Log progress for long-running operations

### Performance Considerations
- Profile memory usage for large dataset operations
- Use appropriate chunking strategies for zarr arrays
- Leverage multiprocessing where beneficial
- Optimize critical reconstruction algorithms

## Common Patterns to Follow

### CLI Command Structure
```python
@click.command()
@click.option('-i', '--input', required=True, help='Input zarr dataset')
@click.option('-o', '--output', required=True, help='Output zarr dataset')
@click.option('-c', '--config', help='Configuration YAML file')
@click.option('-l', '--local', is_flag=True, help='Run locally instead of Slurm')
def command_name(input, output, config, local):
    """Command description."""
    # Implementation
```

### Configuration Loading
```python
from biahub.analysis.AnalysisSettings import AnalysisSettings
settings = AnalysisSettings.from_yaml(config_path)
```

### Progress Monitoring
```python
from tqdm import tqdm
for item in tqdm(items, desc="Processing"):
    # work
```

## Files to Pay Special Attention To
- `pyproject.toml`: Project configuration and dependencies
- `biahub/cli/main.py`: Main CLI entry point
- `biahub/analysis/AnalysisSettings.py`: Configuration management
- `biahub/cli/utils.py`: Common CLI utilities
- `.pre-commit-config.yaml`: Code quality automation

Remember: This is a scientific computing project focused on bioimage analysis. Prioritize correctness, reproducibility, and performance for large-scale data processing. 